# PostgreSQL Rules

## Role
You are an expert in PostgreSQL, database design, and query optimization.

## Schema Design Best Practices

### Table Creation
```sql
-- Use lowercase snake_case for names
CREATE TABLE users (
  id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
  email TEXT UNIQUE NOT NULL,
  full_name TEXT NOT NULL,
  status TEXT DEFAULT 'active' CHECK (status IN ('active', 'inactive', 'suspended')),
  metadata JSONB DEFAULT '{}',
  created_at TIMESTAMPTZ DEFAULT NOW(),
  updated_at TIMESTAMPTZ DEFAULT NOW()
);

-- Add comments for documentation
COMMENT ON TABLE users IS 'Application users';
COMMENT ON COLUMN users.metadata IS 'Flexible JSON storage for user preferences';
```

### Naming Conventions
- Tables: plural, snake_case (`users`, `order_items`)
- Columns: singular, snake_case (`user_id`, `created_at`)
- Primary keys: `id` (UUID preferred) or `table_name_id`
- Foreign keys: `referenced_table_id` (e.g., `user_id`)
- Indexes: `idx_table_column` or `idx_table_column1_column2`
- Constraints: `table_constraint_type` (e.g., `users_email_unique`)

### Data Types
```sql
-- Prefer these types
UUID          -- For primary keys (use gen_random_uuid())
TEXT          -- For strings (no length limit, same performance as VARCHAR)
TIMESTAMPTZ   -- For timestamps (always with timezone)
NUMERIC(p,s)  -- For money/precise decimals
JSONB         -- For flexible JSON (not JSON)
BOOLEAN       -- For true/false
INTEGER       -- For counts, quantities
BIGINT        -- For large numbers, IDs from external systems

-- Avoid these
VARCHAR(n)    -- Use TEXT instead
TIMESTAMP     -- Use TIMESTAMPTZ instead
JSON          -- Use JSONB instead
CHAR(n)       -- Use TEXT instead
```

## Indexes

### When to Index
```sql
-- Primary keys are automatically indexed

-- Foreign keys (ALWAYS index these)
CREATE INDEX idx_orders_user_id ON orders(user_id);

-- Frequently filtered columns
CREATE INDEX idx_users_email ON users(email);

-- Composite index (order matters!)
CREATE INDEX idx_orders_user_status ON orders(user_id, status);

-- Partial index (for common queries)
CREATE INDEX idx_orders_pending ON orders(created_at) 
  WHERE status = 'pending';

-- JSONB index
CREATE INDEX idx_users_metadata ON users USING GIN(metadata);

-- Full-text search
CREATE INDEX idx_posts_search ON posts 
  USING GIN(to_tsvector('english', title || ' ' || content));
```

### Index Analysis
```sql
-- Find missing indexes (slow queries)
SELECT 
  schemaname, tablename, 
  seq_scan, seq_tup_read,
  idx_scan, idx_tup_fetch
FROM pg_stat_user_tables
WHERE seq_scan > idx_scan
ORDER BY seq_tup_read DESC;

-- Find unused indexes
SELECT
  schemaname, tablename, indexname,
  idx_scan, pg_size_pretty(pg_relation_size(indexrelid)) as size
FROM pg_stat_user_indexes
WHERE idx_scan = 0
ORDER BY pg_relation_size(indexrelid) DESC;
```

## Query Patterns

### Pagination
```sql
-- Cursor-based (efficient for large datasets)
SELECT * FROM posts
WHERE created_at < $1  -- cursor from last item
ORDER BY created_at DESC
LIMIT 20;

-- Offset-based (simpler, less efficient)
SELECT * FROM posts
ORDER BY created_at DESC
LIMIT 20 OFFSET 40;
```

### Upsert
```sql
INSERT INTO users (email, full_name)
VALUES ('user@example.com', 'John Doe')
ON CONFLICT (email) 
DO UPDATE SET 
  full_name = EXCLUDED.full_name,
  updated_at = NOW();
```

### Bulk Operations
```sql
-- Bulk insert
INSERT INTO users (email, full_name)
VALUES 
  ('user1@example.com', 'User 1'),
  ('user2@example.com', 'User 2'),
  ('user3@example.com', 'User 3');

-- Bulk update with CASE
UPDATE products
SET price = CASE id
  WHEN 1 THEN 19.99
  WHEN 2 THEN 29.99
  WHEN 3 THEN 39.99
END
WHERE id IN (1, 2, 3);
```

### CTEs (Common Table Expressions)
```sql
WITH active_users AS (
  SELECT * FROM users WHERE status = 'active'
),
user_orders AS (
  SELECT 
    user_id, 
    COUNT(*) as order_count,
    SUM(total) as total_spent
  FROM orders
  GROUP BY user_id
)
SELECT 
  u.email,
  COALESCE(o.order_count, 0) as orders,
  COALESCE(o.total_spent, 0) as spent
FROM active_users u
LEFT JOIN user_orders o ON u.id = o.user_id;
```

## Functions & Triggers

### Updated At Trigger
```sql
-- Function
CREATE OR REPLACE FUNCTION update_updated_at()
RETURNS TRIGGER AS $$
BEGIN
  NEW.updated_at = NOW();
  RETURN NEW;
END;
$$ LANGUAGE plpgsql;

-- Trigger (apply to each table)
CREATE TRIGGER update_users_updated_at
  BEFORE UPDATE ON users
  FOR EACH ROW
  EXECUTE FUNCTION update_updated_at();
```

### Audit Log Trigger
```sql
CREATE TABLE audit_log (
  id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
  table_name TEXT NOT NULL,
  record_id UUID NOT NULL,
  action TEXT NOT NULL,
  old_data JSONB,
  new_data JSONB,
  changed_by UUID,
  changed_at TIMESTAMPTZ DEFAULT NOW()
);

CREATE OR REPLACE FUNCTION audit_trigger()
RETURNS TRIGGER AS $$
BEGIN
  INSERT INTO audit_log (table_name, record_id, action, old_data, new_data)
  VALUES (
    TG_TABLE_NAME,
    COALESCE(NEW.id, OLD.id),
    TG_OP,
    CASE WHEN TG_OP = 'DELETE' THEN to_jsonb(OLD) ELSE NULL END,
    CASE WHEN TG_OP != 'DELETE' THEN to_jsonb(NEW) ELSE NULL END
  );
  RETURN COALESCE(NEW, OLD);
END;
$$ LANGUAGE plpgsql;
```

## Performance

### EXPLAIN ANALYZE
```sql
-- Always analyze slow queries
EXPLAIN (ANALYZE, BUFFERS, FORMAT TEXT)
SELECT * FROM orders
WHERE user_id = 'some-uuid'
AND created_at > NOW() - INTERVAL '30 days';

-- Look for:
-- - Seq Scan on large tables (add index)
-- - High "actual time" values
-- - Loops with high counts
```

### Connection Pooling
```typescript
// Use connection pooler (PgBouncer, Supavisor)
const connectionString = process.env.DATABASE_URL; // Direct
const poolerString = process.env.DATABASE_POOLER_URL; // Pooled

// For serverless, always use pooler
```

### Query Optimization Tips
```sql
-- Use EXISTS instead of IN for subqueries
SELECT * FROM users u
WHERE EXISTS (
  SELECT 1 FROM orders o WHERE o.user_id = u.id
);

-- Avoid SELECT * in production
SELECT id, email, full_name FROM users;

-- Use LIMIT with ORDER BY
SELECT * FROM logs ORDER BY created_at DESC LIMIT 100;
```

## Migrations Best Practices
```sql
-- Always use transactions
BEGIN;

-- Add columns as nullable first
ALTER TABLE users ADD COLUMN phone TEXT;

-- Backfill data
UPDATE users SET phone = '' WHERE phone IS NULL;

-- Then add constraints
ALTER TABLE users ALTER COLUMN phone SET NOT NULL;

COMMIT;

-- Create indexes CONCURRENTLY (no locks)
CREATE INDEX CONCURRENTLY idx_users_phone ON users(phone);
```

## Do's
- Use UUID for primary keys
- Always index foreign keys
- Use TIMESTAMPTZ for timestamps
- Use connection pooling in serverless
- Write migrations as transactions
- Use EXPLAIN ANALYZE for slow queries
- Add comments to tables and columns

## Don'ts
- Don't use VARCHAR with length limits
- Don't store money as FLOAT
- Don't forget to index foreign keys
- Don't use TIMESTAMP without timezone
- Don't run ALTER TABLE without testing
- Don't ignore slow query logs